{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    DataCollatorForLanguageModeling, \n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/cristian.sanchezp/.cache/huggingface/datasets/hakurei___json/hakurei--open-instruct-v1-00713eb9aefc6002/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56572</th>\n",
       "      <td>狗, 猫</td>\n",
       "      <td>Vocabulary problem (inputs: words in english, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355613</th>\n",
       "      <td>(3.0, 2.0, 4.0, 1)</td>\n",
       "      <td>Make a function that takes an array of numbers...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392748</th>\n",
       "      <td>Object-oriented programming (OOP) is a program...</td>\n",
       "      <td>Describe what is meant by object-oriented prog...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344104</th>\n",
       "      <td>Driver</td>\n",
       "      <td>Find out who is responsible for the following ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296291</th>\n",
       "      <td>A potential challenge for the GPT model when t...</td>\n",
       "      <td>Give an example of a potential challenge the G...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197926</th>\n",
       "      <td>int index = 4</td>\n",
       "      <td>What is the first index of the substring \"mod\"...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55520</th>\n",
       "      <td>def average_temperature(city):\\n    temp = 0.0...</td>\n",
       "      <td>I want to know the average temperature of a gi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498796</th>\n",
       "      <td>A diplomatic answer to handle a disagreement a...</td>\n",
       "      <td>Give me a diplomatic answer to handle a disagr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334732</th>\n",
       "      <td>The future of machine learning looks bright. W...</td>\n",
       "      <td>Write an article for a magazine about a topic ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138959</th>\n",
       "      <td>Opportunity cost refers to the potential benef...</td>\n",
       "      <td>Define the term 'opportunity cost' and provide...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482824</th>\n",
       "      <td>The most efficient way to organize your files ...</td>\n",
       "      <td>What is the most efficient way to organize my ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287603</th>\n",
       "      <td>A system that allocates resources on a limited...</td>\n",
       "      <td>Develop a systemfor allocating resources on a ...</td>\n",
       "      <td>The system needs to cover 100 people and alloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173217</th>\n",
       "      <td>Here are some healthy vegetarian recipes to tr...</td>\n",
       "      <td>Find a list of healthy vegetarian recipes.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488689</th>\n",
       "      <td>People have a variety of learning styles, and ...</td>\n",
       "      <td>Describe the different types of learning style...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>Computational thinking is a problem-solving ap...</td>\n",
       "      <td>For the given topic, provide a definition.</td>\n",
       "      <td>Definition of computational thinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162596</th>\n",
       "      <td>The average life expectancy in the US is appro...</td>\n",
       "      <td>What is the average life expectancy in the US.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10845</th>\n",
       "      <td>1. Lentils\\n2. Tofu\\n3. Eggs\\n4. Nuts and nut ...</td>\n",
       "      <td>Make a list of foods that are good sources of ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450709</th>\n",
       "      <td>Texans say \"Remember the Alamo\" to honor the s...</td>\n",
       "      <td>why do texans say \"remember the alamo\"</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279368</th>\n",
       "      <td>- Imagine a world where technology does not ex...</td>\n",
       "      <td>Generate 5 writing prompts.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444310</th>\n",
       "      <td>1. Principle of least privilege\\n\\nCode follow...</td>\n",
       "      <td>Show a code example of each of the following p...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   output  \\\n",
       "56572                                                狗, 猫   \n",
       "355613                                 (3.0, 2.0, 4.0, 1)   \n",
       "392748  Object-oriented programming (OOP) is a program...   \n",
       "344104                                             Driver   \n",
       "296291  A potential challenge for the GPT model when t...   \n",
       "197926                                      int index = 4   \n",
       "55520   def average_temperature(city):\\n    temp = 0.0...   \n",
       "498796  A diplomatic answer to handle a disagreement a...   \n",
       "334732  The future of machine learning looks bright. W...   \n",
       "138959  Opportunity cost refers to the potential benef...   \n",
       "482824  The most efficient way to organize your files ...   \n",
       "287603  A system that allocates resources on a limited...   \n",
       "173217  Here are some healthy vegetarian recipes to tr...   \n",
       "488689  People have a variety of learning styles, and ...   \n",
       "5007    Computational thinking is a problem-solving ap...   \n",
       "162596  The average life expectancy in the US is appro...   \n",
       "10845   1. Lentils\\n2. Tofu\\n3. Eggs\\n4. Nuts and nut ...   \n",
       "450709  Texans say \"Remember the Alamo\" to honor the s...   \n",
       "279368  - Imagine a world where technology does not ex...   \n",
       "444310  1. Principle of least privilege\\n\\nCode follow...   \n",
       "\n",
       "                                              instruction  \\\n",
       "56572   Vocabulary problem (inputs: words in english, ...   \n",
       "355613  Make a function that takes an array of numbers...   \n",
       "392748  Describe what is meant by object-oriented prog...   \n",
       "344104  Find out who is responsible for the following ...   \n",
       "296291  Give an example of a potential challenge the G...   \n",
       "197926  What is the first index of the substring \"mod\"...   \n",
       "55520   I want to know the average temperature of a gi...   \n",
       "498796  Give me a diplomatic answer to handle a disagr...   \n",
       "334732  Write an article for a magazine about a topic ...   \n",
       "138959  Define the term 'opportunity cost' and provide...   \n",
       "482824  What is the most efficient way to organize my ...   \n",
       "287603  Develop a systemfor allocating resources on a ...   \n",
       "173217         Find a list of healthy vegetarian recipes.   \n",
       "488689  Describe the different types of learning style...   \n",
       "5007           For the given topic, provide a definition.   \n",
       "162596     What is the average life expectancy in the US.   \n",
       "10845   Make a list of foods that are good sources of ...   \n",
       "450709             why do texans say \"remember the alamo\"   \n",
       "279368                        Generate 5 writing prompts.   \n",
       "444310  Show a code example of each of the following p...   \n",
       "\n",
       "                                                    input  \n",
       "56572                                                      \n",
       "355613                                                     \n",
       "392748                                                     \n",
       "344104                                                     \n",
       "296291                                                     \n",
       "197926                                                     \n",
       "55520                                                      \n",
       "498796                                                     \n",
       "334732                                                     \n",
       "138959                                                     \n",
       "482824                                                     \n",
       "287603  The system needs to cover 100 people and alloc...  \n",
       "173217                                                     \n",
       "488689                                                     \n",
       "5007                 Definition of computational thinking  \n",
       "162596                                                     \n",
       "10845                                                      \n",
       "450709                                                     \n",
       "279368                                                     \n",
       "444310                                                     "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('hakurei/open-instruct-v1', split='train')\n",
    "dataset.to_pandas().sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    example['prompt'] = f\"{example['instruction']} {example['input']} {example['output']}\"\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\cristian.sanchezp\\.cache\\huggingface\\datasets\\hakurei___json\\hakurei--open-instruct-v1-00713eb9aefc6002\\0.0.0\\e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\\cache-cbda1d7d0dbdd8ca.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(preprocess, remove_columns=['instruction','input','output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137097</th>\n",
       "      <td>Describe how to set up a basic home security s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250179</th>\n",
       "      <td>What is the recipe to make non-spicy Awadhi ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>Rewrite the following sentence using correct c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288131</th>\n",
       "      <td>Describe the characteristics of a cat in 1 sen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150781</th>\n",
       "      <td>Come up with a solution for the following math...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479249</th>\n",
       "      <td>How do I maximize the yield when growing veget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310009</th>\n",
       "      <td>Provide the main reasons why a knife is a more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299123</th>\n",
       "      <td>Complete the following sentence using the give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95115</th>\n",
       "      <td>Tell me about a time when you went out of your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>Generate a list of 5 items we are most likely ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   prompt\n",
       "137097  Describe how to set up a basic home security s...\n",
       "250179  What is the recipe to make non-spicy Awadhi ch...\n",
       "3075    Rewrite the following sentence using correct c...\n",
       "288131  Describe the characteristics of a cat in 1 sen...\n",
       "150781  Come up with a solution for the following math...\n",
       "479249  How do I maximize the yield when growing veget...\n",
       "310009  Provide the main reasons why a knife is a more...\n",
       "299123  Complete the following sentence using the give...\n",
       "95115   Tell me about a time when you went out of your...\n",
       "1603    Generate a list of 5 items we are most likely ..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas().sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\cristian.sanchezp\\.cache\\huggingface\\datasets\\hakurei___json\\hakurei--open-instruct-v1-00713eb9aefc6002\\0.0.0\\e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\\cache-2bc5d54f439219b6.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle(seed=42).select(range(100000)).train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"microsoft/DialoGPT-medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset):\n",
    "    return dataset.map(lambda example: tokenizer(example['prompt'], truncation=True, max_length=128), batched=True, remove_columns=['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628b71ebd0344abbba26ef7dc808ea9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b888af287174ac4ab58eba22c3e3da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = tokenize_dataset(train_dataset)\n",
    "test_dataset = tokenize_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 90000\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainer will use this to process the input and create appropiate batches for training, as we use the generative model, the mlm will be set to false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='../../data/interim/',\n",
    "    num_train_epochs=1, #To keep things fast\n",
    "    per_device_eval_batch_size=4,\n",
    "    per_device_train_batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will do all the heavy lifting\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=test_dataset, \n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b52440de1e44a28853c7b321a13b0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\b\\abs_abjetg6_iu\\croot\\pytorch_1686932924616\\work\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 408488896 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model()\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\xalaxians_env\\Lib\\site-packages\\transformers\\trainer.py:1553\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1554\u001b[0m         args\u001b[39m=\u001b[39margs,\n\u001b[0;32m   1555\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1556\u001b[0m         trial\u001b[39m=\u001b[39mtrial,\n\u001b[0;32m   1557\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1558\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\xalaxians_env\\Lib\\site-packages\\transformers\\trainer.py:1835\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1832\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m   1834\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1835\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1837\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1838\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1839\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1840\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1841\u001b[0m ):\n\u001b[0;32m   1842\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1843\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\xalaxians_env\\Lib\\site-packages\\transformers\\trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2676\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   2678\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2679\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(model, inputs)\n\u001b[0;32m   2681\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2682\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\xalaxians_env\\Lib\\site-packages\\transformers\\trainer.py:2704\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2702\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2703\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2704\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[0;32m   2705\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2706\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2707\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\xalaxians_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\xalaxians_env\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1105\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1103\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(lm_logits\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   1104\u001b[0m \u001b[39m# Shift so that tokens < n predict n\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m shift_logits \u001b[39m=\u001b[39m lm_logits[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m   1106\u001b[0m shift_labels \u001b[39m=\u001b[39m labels[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m   1107\u001b[0m \u001b[39m# Flatten the tokens\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\b\\abs_abjetg6_iu\\croot\\pytorch_1686932924616\\work\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 408488896 bytes."
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('xalaxians_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b94f8552009d7fcb73af2742ecfa37a7f8bbb6f8e5c677622085453cebaad380"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
