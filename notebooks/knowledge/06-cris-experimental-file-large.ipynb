{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(url: str) -> str:\n",
    "    reader = PdfReader(url)\n",
    "\n",
    "    text = ''\n",
    "    for page_num in range(len(reader.pages)):\n",
    "        page = reader.pages[page_num]\n",
    "        text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../../data/raw/dataset/'\n",
    "content = []\n",
    "instruction = []\n",
    "output = []\n",
    "with os.scandir(base_path) as entries:\n",
    "    for entry in entries:\n",
    "        if entry.name.endswith(\".pdf\"):\n",
    "            text = extract_text_from_pdf(base_path+entry.name)\n",
    "            components = text.split(\":\")\n",
    "\n",
    "            name = components[1].replace('Name', '').replace('Description','')#Name and Description\n",
    "            description = components[2].replace('Data', '')# Description and Data\n",
    "            data = text.split(\":\")[3].replace('In-depth Analysis', '').replace('-', '')\n",
    "            analysis = text.split(\":\")[4] # In-depth Analysis\n",
    "            text = name + ' '+ description + ' '+ data + ' '+analysis\n",
    "            content.append(text.replace('\\n', ''))\n",
    "        elif entry.name.endswith(\".txt\"):\n",
    "            id = lambda x: x\n",
    "            file = open(base_path+entry.name,\"r+\", encoding=\"utf8\")\n",
    "            lines = file.readlines()\n",
    "            text = ' '.join(lines)\n",
    "            content.append(text)\n",
    "            file.close()\n",
    "\n",
    "dataset = {'prompt': content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/processed/context.txt', 'w', encoding='utf8') as f:\n",
    "    for c in content:\n",
    "        f.write(c)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('../../data/processed/context.txt', encoding='utf8')\n",
    "\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(index.query('What is the Xalaxians collective consciousness?', llm=ChatOpenAI()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('xalaxians_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b94f8552009d7fcb73af2742ecfa37a7f8bbb6f8e5c677622085453cebaad380"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
